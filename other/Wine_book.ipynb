{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Using only the standard Python API (ie. primitives and standard libraries), \n",
    "       # print the color intensity of the 3 wines in each category with the greatest alcohol content.  \n",
    "       # Put another way, for each type of wine weâ€™d like to order wines by alcohol content but report \n",
    "       # only the color intensity for the most alcoholic among them. In total there should be nine \n",
    "       # values emitted, 3 wines from each of 3 categories.\n",
    "# B) Z-score normalize each column in the dataset\n",
    "# C) Using a quantitative method, determine whether wines of the same type are more chemically similar \n",
    "#      to one another than wines from different varieties.  Feel free to add a written description of \n",
    "#      your reasoning to augment any statistical tests, plots, or code you use to establish a conclusion.  \n",
    "\n",
    "columns = [\"Wine_Type\", \"Alcohol\", \"Malic_acid\", \"Ash\", \"Alcalinity_of_ash\", \"Magnesium\", \"Total_phenols\", \"Flavanoids\", \"Nonflavanoid_phenols\", \"Proanthocyanins\", \"Color_intensity\", \"Hue\", \"OD280/OD315_of_diluted_wines\", \"Proline\"]\n",
    "data = ['1,14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065', '1,13.2,1.78,2.14,11.2,100,2.65,2.76,.26,1.28,4.38,1.05,3.4,1050', '1,13.16,2.36,2.67,18.6,101,2.8,3.24,.3,2.81,5.68,1.03,3.17,1185', '1,14.37,1.95,2.5,16.8,113,3.85,3.49,.24,2.18,7.8,.86,3.45,1480', '1,13.24,2.59,2.87,21,118,2.8,2.69,.39,1.82,4.32,1.04,2.93,735', '1,14.2,1.76,2.45,15.2,112,3.27,3.39,.34,1.97,6.75,1.05,2.85,1450', '1,14.39,1.87,2.45,14.6,96,2.5,2.52,.3,1.98,5.25,1.02,3.58,1290', '1,14.06,2.15,2.61,17.6,121,2.6,2.51,.31,1.25,5.05,1.06,3.58,1295', '1,14.83,1.64,2.17,14,97,2.8,2.98,.29,1.98,5.2,1.08,2.85,1045', '1,13.86,1.35,2.27,16,98,2.98,3.15,.22,1.85,7.22,1.01,3.55,1045', '1,14.1,2.16,2.3,18,105,2.95,3.32,.22,2.38,5.75,1.25,3.17,1510', '1,14.12,1.48,2.32,16.8,95,2.2,2.43,.26,1.57,5,1.17,2.82,1280', '1,13.75,1.73,2.41,16,89,2.6,2.76,.29,1.81,5.6,1.15,2.9,1320', '1,14.75,1.73,2.39,11.4,91,3.1,3.69,.43,2.81,5.4,1.25,2.73,1150', '1,14.38,1.87,2.38,12,102,3.3,3.64,.29,2.96,7.5,1.2,3,1547', '1,13.63,1.81,2.7,17.2,112,2.85,2.91,.3,1.46,7.3,1.28,2.88,1310', '1,14.3,1.92,2.72,20,120,2.8,3.14,.33,1.97,6.2,1.07,2.65,1280', '1,13.83,1.57,2.62,20,115,2.95,3.4,.4,1.72,6.6,1.13,2.57,1130', '1,14.19,1.59,2.48,16.5,108,3.3,3.93,.32,1.86,8.7,1.23,2.82,1680', '1,13.64,3.1,2.56,15.2,116,2.7,3.03,.17,1.66,5.1,.96,3.36,845', '1,14.06,1.63,2.28,16,126,3,3.17,.24,2.1,5.65,1.09,3.71,780', '1,12.93,3.8,2.65,18.6,102,2.41,2.41,.25,1.98,4.5,1.03,3.52,770', '1,13.71,1.86,2.36,16.6,101,2.61,2.88,.27,1.69,3.8,1.11,4,1035', '1,12.85,1.6,2.52,17.8,95,2.48,2.37,.26,1.46,3.93,1.09,3.63,1015', '1,13.5,1.81,2.61,20,96,2.53,2.61,.28,1.66,3.52,1.12,3.82,845', '1,13.05,2.05,3.22,25,124,2.63,2.68,.47,1.92,3.58,1.13,3.2,830', '1,13.39,1.77,2.62,16.1,93,2.85,2.94,.34,1.45,4.8,.92,3.22,1195', '1,13.3,1.72,2.14,17,94,2.4,2.19,.27,1.35,3.95,1.02,2.77,1285', '1,13.87,1.9,2.8,19.4,107,2.95,2.97,.37,1.76,4.5,1.25,3.4,915', '1,14.02,1.68,2.21,16,96,2.65,2.33,.26,1.98,4.7,1.04,3.59,1035', '1,13.73,1.5,2.7,22.5,101,3,3.25,.29,2.38,5.7,1.19,2.71,1285', '1,13.58,1.66,2.36,19.1,106,2.86,3.19,.22,1.95,6.9,1.09,2.88,1515', '1,13.68,1.83,2.36,17.2,104,2.42,2.69,.42,1.97,3.84,1.23,2.87,990', '1,13.76,1.53,2.7,19.5,132,2.95,2.74,.5,1.35,5.4,1.25,3,1235', '1,13.51,1.8,2.65,19,110,2.35,2.53,.29,1.54,4.2,1.1,2.87,1095', '1,13.48,1.81,2.41,20.5,100,2.7,2.98,.26,1.86,5.1,1.04,3.47,920', '1,13.28,1.64,2.84,15.5,110,2.6,2.68,.34,1.36,4.6,1.09,2.78,880', '1,13.05,1.65,2.55,18,98,2.45,2.43,.29,1.44,4.25,1.12,2.51,1105', '1,13.07,1.5,2.1,15.5,98,2.4,2.64,.28,1.37,3.7,1.18,2.69,1020', '1,14.22,3.99,2.51,13.2,128,3,3.04,.2,2.08,5.1,.89,3.53,760', '1,13.56,1.71,2.31,16.2,117,3.15,3.29,.34,2.34,6.13,.95,3.38,795', '1,13.41,3.84,2.12,18.8,90,2.45,2.68,.27,1.48,4.28,.91,3,1035', '1,13.88,1.89,2.59,15,101,3.25,3.56,.17,1.7,5.43,.88,3.56,1095', '1,13.24,3.98,2.29,17.5,103,2.64,2.63,.32,1.66,4.36,.82,3,680', '1,13.05,1.77,2.1,17,107,3,3,.28,2.03,5.04,.88,3.35,885', '1,14.21,4.04,2.44,18.9,111,2.85,2.65,.3,1.25,5.24,.87,3.33,1080', '1,14.38,3.59,2.28,16,102,3.25,3.17,.27,2.19,4.9,1.04,3.44,1065', '1,13.9,1.68,2.12,16,101,3.1,3.39,.21,2.14,6.1,.91,3.33,985', '1,14.1,2.02,2.4,18.8,103,2.75,2.92,.32,2.38,6.2,1.07,2.75,1060', '1,13.94,1.73,2.27,17.4,108,2.88,3.54,.32,2.08,8.90,1.12,3.1,1260', '1,13.05,1.73,2.04,12.4,92,2.72,3.27,.17,2.91,7.2,1.12,2.91,1150', '1,13.83,1.65,2.6,17.2,94,2.45,2.99,.22,2.29,5.6,1.24,3.37,1265', '1,13.82,1.75,2.42,14,111,3.88,3.74,.32,1.87,7.05,1.01,3.26,1190', '1,13.77,1.9,2.68,17.1,115,3,2.79,.39,1.68,6.3,1.13,2.93,1375', '1,13.74,1.67,2.25,16.4,118,2.6,2.9,.21,1.62,5.85,.92,3.2,1060', '1,13.56,1.73,2.46,20.5,116,2.96,2.78,.2,2.45,6.25,.98,3.03,1120', '1,14.22,1.7,2.3,16.3,118,3.2,3,.26,2.03,6.38,.94,3.31,970', '1,13.29,1.97,2.68,16.8,102,3,3.23,.31,1.66,6,1.07,2.84,1270', '1,13.72,1.43,2.5,16.7,108,3.4,3.67,.19,2.04,6.8,.89,2.87,1285', '2,12.37,.94,1.36,10.6,88,1.98,.57,.28,.42,1.95,1.05,1.82,520', '2,12.33,1.1,2.28,16,101,2.05,1.09,.63,.41,3.27,1.25,1.67,680', '2,12.64,1.36,2.02,16.8,100,2.02,1.41,.53,.62,5.75,.98,1.59,450', '2,13.67,1.25,1.92,18,94,2.1,1.79,.32,.73,3.8,1.23,2.46,630', '2,12.37,1.13,2.16,19,87,3.5,3.1,.19,1.87,4.45,1.22,2.87,420', '2,12.17,1.45,2.53,19,104,1.89,1.75,.45,1.03,2.95,1.45,2.23,355', '2,12.37,1.21,2.56,18.1,98,2.42,2.65,.37,2.08,4.6,1.19,2.3,678', '2,13.11,1.01,1.7,15,78,2.98,3.18,.26,2.28,5.3,1.12,3.18,502', '2,12.37,1.17,1.92,19.6,78,2.11,2,.27,1.04,4.68,1.12,3.48,510', '2,13.34,.94,2.36,17,110,2.53,1.3,.55,.42,3.17,1.02,1.93,750', '2,12.21,1.19,1.75,16.8,151,1.85,1.28,.14,2.5,2.85,1.28,3.07,718', '2,12.29,1.61,2.21,20.4,103,1.1,1.02,.37,1.46,3.05,.906,1.82,870', '2,13.86,1.51,2.67,25,86,2.95,2.86,.21,1.87,3.38,1.36,3.16,410', '2,13.49,1.66,2.24,24,87,1.88,1.84,.27,1.03,3.74,.98,2.78,472', '2,12.99,1.67,2.6,30,139,3.3,2.89,.21,1.96,3.35,1.31,3.5,985', '2,11.96,1.09,2.3,21,101,3.38,2.14,.13,1.65,3.21,.99,3.13,886', '2,11.66,1.88,1.92,16,97,1.61,1.57,.34,1.15,3.8,1.23,2.14,428', '2,13.03,.9,1.71,16,86,1.95,2.03,.24,1.46,4.6,1.19,2.48,392', '2,11.84,2.89,2.23,18,112,1.72,1.32,.43,.95,2.65,.96,2.52,500', '2,12.33,.99,1.95,14.8,136,1.9,1.85,.35,2.76,3.4,1.06,2.31,750', '2,12.7,3.87,2.4,23,101,2.83,2.55,.43,1.95,2.57,1.19,3.13,463', '2,12,.92,2,19,86,2.42,2.26,.3,1.43,2.5,1.38,3.12,278', '2,12.72,1.81,2.2,18.8,86,2.2,2.53,.26,1.77,3.9,1.16,3.14,714', '2,12.08,1.13,2.51,24,78,2,1.58,.4,1.4,2.2,1.31,2.72,630', '2,13.05,3.86,2.32,22.5,85,1.65,1.59,.61,1.62,4.8,.84,2.01,515', '2,11.84,.89,2.58,18,94,2.2,2.21,.22,2.35,3.05,.79,3.08,520', '2,12.67,.98,2.24,18,99,2.2,1.94,.3,1.46,2.62,1.23,3.16,450', '2,12.16,1.61,2.31,22.8,90,1.78,1.69,.43,1.56,2.45,1.33,2.26,495', '2,11.65,1.67,2.62,26,88,1.92,1.61,.4,1.34,2.6,1.36,3.21,562', '2,11.64,2.06,2.46,21.6,84,1.95,1.69,.48,1.35,2.8,1,2.75,680', '2,12.08,1.33,2.3,23.6,70,2.2,1.59,.42,1.38,1.74,1.07,3.21,625', '2,12.08,1.83,2.32,18.5,81,1.6,1.5,.52,1.64,2.4,1.08,2.27,480', '2,12,1.51,2.42,22,86,1.45,1.25,.5,1.63,3.6,1.05,2.65,450', '2,12.69,1.53,2.26,20.7,80,1.38,1.46,.58,1.62,3.05,.96,2.06,495', '2,12.29,2.83,2.22,18,88,2.45,2.25,.25,1.99,2.15,1.15,3.3,290', '2,11.62,1.99,2.28,18,98,3.02,2.26,.17,1.35,3.25,1.16,2.96,345', '2,12.47,1.52,2.2,19,162,2.5,2.27,.32,3.28,2.6,1.16,2.63,937', '2,11.81,2.12,2.74,21.5,134,1.6,.99,.14,1.56,2.5,.95,2.26,625', '2,12.29,1.41,1.98,16,85,2.55,2.5,.29,1.77,2.9,1.23,2.74,428', '2,12.37,1.07,2.1,18.5,88,3.52,3.75,.24,1.95,4.5,1.04,2.77,660', '2,12.29,3.17,2.21,18,88,2.85,2.99,.45,2.81,2.3,1.42,2.83,406', '2,12.08,2.08,1.7,17.5,97,2.23,2.17,.26,1.4,3.3,1.27,2.96,710', '2,12.6,1.34,1.9,18.5,88,1.45,1.36,.29,1.35,2.45,1.04,2.77,562', '2,12.34,2.45,2.46,21,98,2.56,2.11,.34,1.31,2.8,.8,3.38,438', '2,11.82,1.72,1.88,19.5,86,2.5,1.64,.37,1.42,2.06,.94,2.44,415', '2,12.51,1.73,1.98,20.5,85,2.2,1.92,.32,1.48,2.94,1.04,3.57,672', '2,12.42,2.55,2.27,22,90,1.68,1.84,.66,1.42,2.7,.86,3.3,315', '2,12.25,1.73,2.12,19,80,1.65,2.03,.37,1.63,3.4,1,3.17,510', '2,12.72,1.75,2.28,22.5,84,1.38,1.76,.48,1.63,3.3,.88,2.42,488', '2,12.22,1.29,1.94,19,92,2.36,2.04,.39,2.08,2.7,.86,3.02,312', '2,11.61,1.35,2.7,20,94,2.74,2.92,.29,2.49,2.65,.96,3.26,680', '2,11.46,3.74,1.82,19.5,107,3.18,2.58,.24,3.58,2.9,.75,2.81,562', '2,12.52,2.43,2.17,21,88,2.55,2.27,.26,1.22,2,.9,2.78,325', '2,11.76,2.68,2.92,20,103,1.75,2.03,.6,1.05,3.8,1.23,2.5,607', '2,11.41,.74,2.5,21,88,2.48,2.01,.42,1.44,3.08,1.1,2.31,434', '2,12.08,1.39,2.5,22.5,84,2.56,2.29,.43,1.04,2.9,.93,3.19,385', '2,11.03,1.51,2.2,21.5,85,2.46,2.17,.52,2.01,1.9,1.71,2.87,407', '2,11.82,1.47,1.99,20.8,86,1.98,1.6,.3,1.53,1.95,.95,3.33,495', '2,12.42,1.61,2.19,22.5,108,2,2.09,.34,1.61,2.06,1.06,2.96,345', '2,12.77,3.43,1.98,16,80,1.63,1.25,.43,.83,3.4,.7,2.12,372', '2,12,3.43,2,19,87,2,1.64,.37,1.87,1.28,.93,3.05,564', '2,11.45,2.4,2.42,20,96,2.9,2.79,.32,1.83,3.25,.8,3.39,625', '2,11.56,2.05,3.23,28.5,119,3.18,5.08,.47,1.87,6,.93,3.69,465', '2,12.42,4.43,2.73,26.5,102,2.2,2.13,.43,1.71,2.08,.92,3.12,365', '2,13.05,5.8,2.13,21.5,86,2.62,2.65,.3,2.01,2.6,.73,3.1,380', '2,11.87,4.31,2.39,21,82,2.86,3.03,.21,2.91,2.8,.75,3.64,380', '2,12.07,2.16,2.17,21,85,2.6,2.65,.37,1.35,2.76,.86,3.28,378', '2,12.43,1.53,2.29,21.5,86,2.74,3.15,.39,1.77,3.94,.69,2.84,352', '2,11.79,2.13,2.78,28.5,92,2.13,2.24,.58,1.76,3,.97,2.44,466', '2,12.37,1.63,2.3,24.5,88,2.22,2.45,.4,1.9,2.12,.89,2.78,342', '2,12.04,4.3,2.38,22,80,2.1,1.75,.42,1.35,2.6,.79,2.57,580', '3,12.86,1.35,2.32,18,122,1.51,1.25,.21,.94,4.1,.76,1.29,630', '3,12.88,2.99,2.4,20,104,1.3,1.22,.24,.83,5.4,.74,1.42,530', '3,12.81,2.31,2.4,24,98,1.15,1.09,.27,.83,5.7,.66,1.36,560', '3,12.7,3.55,2.36,21.5,106,1.7,1.2,.17,.84,5,.78,1.29,600', '3,12.51,1.24,2.25,17.5,85,2,.58,.6,1.25,5.45,.75,1.51,650', '3,12.6,2.46,2.2,18.5,94,1.62,.66,.63,.94,7.1,.73,1.58,695', '3,12.25,4.72,2.54,21,89,1.38,.47,.53,.8,3.85,.75,1.27,720', '3,12.53,5.51,2.64,25,96,1.79,.6,.63,1.1,5,.82,1.69,515', '3,13.49,3.59,2.19,19.5,88,1.62,.48,.58,.88,5.7,.81,1.82,580', '3,12.84,2.96,2.61,24,101,2.32,.6,.53,.81,4.92,.89,2.15,590', '3,12.93,2.81,2.7,21,96,1.54,.5,.53,.75,4.6,.77,2.31,600', '3,13.36,2.56,2.35,20,89,1.4,.5,.37,.64,5.6,.7,2.47,780', '3,13.52,3.17,2.72,23.5,97,1.55,.52,.5,.55,4.35,.89,2.06,520', '3,13.62,4.95,2.35,20,92,2,.8,.47,1.02,4.4,.91,2.05,550', '3,12.25,3.88,2.2,18.5,112,1.38,.78,.29,1.14,8.21,.65,2,855', '3,13.16,3.57,2.15,21,102,1.5,.55,.43,1.3,4,.6,1.68,830', '3,13.88,5.04,2.23,20,80,.98,.34,.4,.68,4.9,.58,1.33,415', '3,12.87,4.61,2.48,21.5,86,1.7,.65,.47,.86,7.65,.54,1.86,625', '3,13.32,3.24,2.38,21.5,92,1.93,.76,.45,1.25,8.42,.55,1.62,650', '3,13.08,3.9,2.36,21.5,113,1.41,1.39,.34,1.14,9.40,.57,1.33,550', '3,13.5,3.12,2.62,24,123,1.4,1.57,.22,1.25,8.60,.59,1.3,500', '3,12.79,2.67,2.48,22,112,1.48,1.36,.24,1.26,10.8,.48,1.47,480', '3,13.11,1.9,2.75,25.5,116,2.2,1.28,.26,1.56,7.1,.61,1.33,425', '3,13.23,3.3,2.28,18.5,98,1.8,.83,.61,1.87,10.52,.56,1.51,675', '3,12.58,1.29,2.1,20,103,1.48,.58,.53,1.4,7.6,.58,1.55,640', '3,13.17,5.19,2.32,22,93,1.74,.63,.61,1.55,7.9,.6,1.48,725', '3,13.84,4.12,2.38,19.5,89,1.8,.83,.48,1.56,9.01,.57,1.64,480', '3,12.45,3.03,2.64,27,97,1.9,.58,.63,1.14,7.5,.67,1.73,880', '3,14.34,1.68,2.7,25,98,2.8,1.31,.53,2.7,13,.57,1.96,660', '3,13.48,1.67,2.64,22.5,89,2.6,1.1,.52,2.29,11.75,.57,1.78,620', '3,12.36,3.83,2.38,21,88,2.3,.92,.5,1.04,7.65,.56,1.58,520', '3,13.69,3.26,2.54,20,107,1.83,.56,.5,.8,5.88,.96,1.82,680', '3,12.85,3.27,2.58,22,106,1.65,.6,.6,.96,5.58,.87,2.11,570', '3,12.96,3.45,2.35,18.5,106,1.39,.7,.4,.94,5.28,.68,1.75,675', '3,13.78,2.76,2.3,22,90,1.35,.68,.41,1.03,9.58,.7,1.68,615', '3,13.73,4.36,2.26,22.5,88,1.28,.47,.52,1.15,6.62,.78,1.75,520', '3,13.45,3.7,2.6,23,111,1.7,.92,.43,1.46,10.68,.85,1.56,695', '3,12.82,3.37,2.3,19.5,88,1.48,.66,.4,.97,10.26,.72,1.75,685', '3,13.58,2.58,2.69,24.5,105,1.55,.84,.39,1.54,8.66,.74,1.8,750', '3,13.4,4.6,2.86,25,112,1.98,.96,.27,1.11,8.5,.67,1.92,630', '3,12.2,3.03,2.32,19,96,1.25,.49,.4,.73,5.5,.66,1.83,510', '3,12.77,2.39,2.28,19.5,86,1.39,.51,.48,.64,9.899999,.57,1.63,470', '3,14.16,2.51,2.48,20,91,1.68,.7,.44,1.24,9.7,.62,1.71,660', '3,13.71,5.65,2.45,20.5,95,1.68,.61,.52,1.06,7.7,.64,1.74,740', '3,13.4,3.91,2.48,23,102,1.8,.75,.43,1.41,7.3,.7,1.56,750', '3,13.27,4.28,2.26,20,120,1.59,.69,.43,1.35,10.2,.59,1.56,835', '3,13.17,2.59,2.37,20,120,1.65,.68,.53,1.46,9.3,.6,1.62,840', '3,14.13,4.1,2.74,24.5,96,2.05,.76,.56,1.35,9.2,.61,1.6,560']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.1\n",
    "def load_data():\n",
    "    result = []\n",
    "    for d in data:\n",
    "        v = d.split(\",\")\n",
    "        line = []\n",
    "        for _v in v:\n",
    "            line.append(float(_v))\n",
    "        result.append(line)\n",
    "    return result\n",
    "\n",
    "data_set = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Wine 1.0----\n",
      "alcohol:14.83,color:5.2\n",
      "alcohol:14.75,color:5.4\n",
      "alcohol:14.39,color:5.25\n",
      "----Wine 2.0----\n",
      "alcohol:13.86,color:3.38\n",
      "alcohol:13.67,color:3.8\n",
      "alcohol:13.49,color:3.74\n",
      "----Wine 3.0----\n",
      "alcohol:14.34,color:13.0\n",
      "alcohol:14.16,color:9.7\n",
      "alcohol:14.13,color:9.2\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "wines = defaultdict(list)\n",
    "for line in data_set:\n",
    "    wines[line[0]].append(line)\n",
    "        \n",
    "alcohol_col = 1\n",
    "color_col = 10\n",
    "\n",
    "def get_top_3(w):\n",
    "    _w = sorted(w, key=lambda v:v[alcohol_col], reverse=True)\n",
    "    return _w[:3]\n",
    "\n",
    "for w in wines.keys():\n",
    "    top3 = get_top_3(wines[w])\n",
    "    print(\"----Wine {}----\".format(w))\n",
    "    for t in top3:\n",
    "        print(\"alcohol:{},color:{}\".format(t[alcohol_col], t[color_col]))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "data_set_np = np.array(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==column:Alcohol===\n",
      "[ 1.51861254  0.24628963  0.19687903  1.69154964  0.29570023  1.48155459\n",
      "  1.71625494  1.3086175   2.25977152  1.0615645   1.3580281   1.38273339\n",
      "  0.92568536  2.16095032  1.70390229  0.77745356  1.60508109  1.02450655\n",
      "  1.46920194  0.78980621  1.3086175  -0.08723191  0.87627476 -0.18605311\n",
      "  0.61686912  0.06099988  0.48098997  0.36981612  1.07391715  1.2592069\n",
      "  0.90098006  0.71569031  0.83921681  0.93803801  0.62922177  0.59216382\n",
      "  0.34511082  0.06099988  0.08570518  1.50625989  0.69098501  0.50569527\n",
      "  1.0862698   0.29570023  0.06099988  1.49390724  1.70390229  1.1109751\n",
      "  1.3580281   1.1603857   0.06099988  1.02450655  1.01215391  0.95039066\n",
      "  0.91333271  0.69098501  1.50625989  0.35746347  0.88862741 -0.77898029\n",
      " -0.82839089 -0.44545875  0.82686416 -0.77898029 -1.02603329 -0.77898029\n",
      "  0.13511578 -0.77898029  0.41922672 -0.97662269 -0.87780149  1.0615645\n",
      "  0.60451647 -0.01311602 -1.28543893 -1.65601842  0.03629458 -1.43367073\n",
      " -0.82839089 -0.37134286 -1.23602833 -0.34663756 -1.13720713  0.06099988\n",
      " -1.43367073 -0.4084008  -1.03838594 -1.66837107 -1.68072372 -1.13720713\n",
      " -1.13720713 -1.23602833 -0.38369551 -0.87780149 -1.70542902 -0.6554538\n",
      " -1.47072867 -0.87780149 -0.77898029 -0.87780149 -1.13720713 -0.49486935\n",
      " -0.81603824 -1.45837602 -0.6060432  -0.71721705 -0.92721209 -0.34663756\n",
      " -0.96427004 -1.71778167 -1.90307141 -0.59369055 -1.53249192 -1.96483466\n",
      " -1.13720713 -2.43423535 -1.45837602 -0.71721705 -0.28487431 -1.23602833\n",
      " -1.91542406 -1.77954492 -0.71721705  0.06099988 -1.39661278 -1.14955978\n",
      " -0.7048644  -1.49543397 -0.77898029 -1.18661773 -0.17370046 -0.14899516\n",
      " -0.23546371 -0.37134286 -0.6060432  -0.49486935 -0.92721209 -0.5813379\n",
      "  0.60451647 -0.19840576 -0.08723191  0.44393202  0.64157442  0.76510091\n",
      " -0.92721209  0.19687903  1.0862698  -0.16134781  0.39452142  0.09805783\n",
      "  0.61686912 -0.26016901  0.13511578  0.28334758 -0.51957465  0.20923168\n",
      "  1.0368592  -0.6801591   1.65449169  0.59216382 -0.79133294  0.85156946\n",
      " -0.18605311 -0.05017396  0.96274331  0.90098006  0.55510587 -0.22311106\n",
      "  0.71569031  0.49334262 -0.98897534 -0.28487431  1.43214399  0.87627476\n",
      "  0.49334262  0.33275817  0.20923168  1.39508604]\n",
      "==column:Malic_acid===\n",
      "[-0.5622498  -0.49941338  0.02123125 -0.34681064  0.22769377 -0.51736664\n",
      " -0.4186237  -0.16727801 -0.62508622 -0.88540853 -0.15830138 -0.76871232\n",
      " -0.54429654 -0.54429654 -0.4186237  -0.47248348 -0.37374054 -0.68792264\n",
      " -0.66996938  0.68550197 -0.63406285  1.31386618 -0.42760033 -0.66099274\n",
      " -0.47248348 -0.25704433 -0.50839001 -0.55327317 -0.3916938  -0.58917969\n",
      " -0.75075906 -0.60713296 -0.45453022 -0.72382916 -0.48146012 -0.47248348\n",
      " -0.62508622 -0.61610959 -0.75075906  1.48442217 -0.5622498   1.3497727\n",
      " -0.40067043  1.47544554 -0.50839001  1.52930533  1.12535692 -0.58917969\n",
      " -0.28397422 -0.54429654 -0.54429654 -0.61610959 -0.52634327 -0.3916938\n",
      " -0.59815632 -0.54429654 -0.57122643 -0.32885738 -0.81359548 -1.25345042\n",
      " -1.10982432 -0.8764319  -0.97517485 -1.08289442 -0.79564222 -1.01108137\n",
      " -1.190614   -1.0469879  -1.25345042 -1.02903463 -0.65201611 -0.74178243\n",
      " -0.60713296 -0.59815632 -1.11880095 -0.40964706 -1.28935695  0.49699271\n",
      " -1.20856726  1.3767026  -1.27140368 -0.47248348 -1.08289442  1.36772596\n",
      " -1.29833358 -1.21754389 -0.65201611 -0.59815632 -0.2480677  -0.90336179\n",
      " -0.45453022 -0.74178243 -0.72382916  0.44313292 -0.31090412 -0.7328058\n",
      " -0.19420791 -0.83154874 -1.13675421  0.74833839 -0.23011443 -0.89438516\n",
      "  0.10202093 -0.55327317 -0.54429654  0.19178724 -0.54429654 -0.52634327\n",
      " -0.93926832 -0.88540853  1.26000639  0.08406767  0.30848345 -1.43298305\n",
      " -0.849502   -0.74178243 -0.77768895 -0.65201611  0.98173081  0.98173081\n",
      "  0.05713777 -0.25704433  1.87939396  3.10919247  1.77167438 -0.15830138\n",
      " -0.72382916 -0.18523128 -0.63406285  1.76269775 -0.88540853  0.58675903\n",
      " -0.02365191  1.08945039 -0.98415148  0.11099756  2.13971627  2.84887015\n",
      "  1.12535692  0.55982913  0.42517966  0.20076388  0.74833839  2.34617879\n",
      "  1.38567923  1.10740365  2.42696848  2.04097332  0.81117481  1.40363249\n",
      "  0.70345524  0.29950682 -0.3916938   0.8650346  -0.93926832  2.56161795\n",
      "  1.60111838  0.62266555 -0.58917969 -0.59815632  1.34079607  0.82912808\n",
      "  0.83810471  0.99968408  0.3802965   1.81655754  1.22409986  0.92787102\n",
      "  0.21871714  2.03199669  0.62266555  0.04816114  0.15588072  2.974543\n",
      "  1.41260912  1.74474449  0.22769377  1.58316512]\n",
      "==column:Ash===\n",
      "[ 0.23205254 -0.82799632  1.10933436  0.4879264   1.84040254  0.30515936\n",
      "  0.30515936  0.89001391 -0.7183361  -0.352802   -0.24314178 -0.17003496\n",
      "  0.15894572  0.0858389   0.0492855   1.21899459  1.29210141  0.92656731\n",
      "  0.41481959  0.70724686 -0.3162486   1.03622754 -0.02382132  0.56103322\n",
      "  0.89001391  3.11977186  0.92656731 -0.82799632  1.58452868 -0.57212246\n",
      "  1.21899459 -0.02382132 -0.02382132  1.21899459  1.03622754  0.15894572\n",
      "  1.73074231  0.67069345 -0.97420996  0.52447981 -0.20658837 -0.90110314\n",
      "  0.81690709 -0.27969519 -0.97420996  0.26860595 -0.3162486  -0.90110314\n",
      "  0.12239231 -0.352802   -1.19353041  0.8534605   0.19549913  1.14588777\n",
      " -0.42590882  0.34171277 -0.24314178  1.14588777  0.4879264  -3.67916223\n",
      " -0.3162486  -1.26663723 -1.63217132 -0.75488951  0.59758663  0.70724686\n",
      " -2.43634632 -1.63217132 -0.02382132 -2.25357928 -0.57212246  1.10933436\n",
      " -0.46246223  0.8534605  -0.24314178 -1.63217132 -2.39979292 -0.49901564\n",
      " -1.5225111   0.12239231 -1.33974405 -0.60867587  0.52447981 -0.17003496\n",
      "  0.78035368 -0.46246223 -0.20658837  0.92656731  0.34171277 -0.24314178\n",
      " -0.17003496  0.19549913 -0.38935541 -0.53556905 -0.3162486  -0.60867587\n",
      "  1.36520822 -1.41285087 -0.97420996 -0.57212246 -2.43634632 -1.70527814\n",
      "  0.34171277 -1.77838496 -1.41285087 -0.352802   -0.90110314 -0.3162486\n",
      " -1.55906451  1.21899459 -1.99770541 -0.7183361   2.02316959  0.4879264\n",
      "  0.4879264  -0.60867587 -1.37629746 -0.64522928 -1.41285087 -1.33974405\n",
      "  0.19549913  3.15632527  1.32865481 -0.86454973  0.0858389  -0.7183361\n",
      " -0.27969519  1.51142186 -0.24314178  0.0492855  -0.17003496  0.12239231\n",
      "  0.12239231 -0.02382132 -0.42590882 -0.60867587  0.63414004  0.99967413\n",
      " -0.64522928  0.89001391  1.21899459 -0.06037473  1.29210141 -0.06037473\n",
      " -0.60867587 -0.79144291 -0.49901564  0.41481959  0.0492855  -0.02382132\n",
      "  0.92656731  0.41481959  1.40176163 -0.3162486  -0.97420996 -0.17003496\n",
      "  0.0492855   0.99967413  1.21899459  0.99967413  0.0492855   0.63414004\n",
      "  0.78035368 -0.06037473 -0.24314178 -0.38935541  0.8534605  -0.24314178\n",
      "  1.18244118  1.80384913 -0.17003496 -0.3162486   0.41481959  0.30515936\n",
      "  0.41481959 -0.38935541  0.01273209  1.36520822]\n",
      "==column:Alcalinity_of_ash===\n",
      "[-1.16959318e+00 -2.49084714e+00 -2.68738198e-01 -8.09251184e-01\n",
      "  4.51945783e-01 -1.28970717e+00 -1.46987817e+00 -5.69023190e-01\n",
      " -1.65004916e+00 -1.04947918e+00 -4.48909194e-01 -8.09251184e-01\n",
      " -1.04947918e+00 -2.43079014e+00 -2.25061915e+00 -6.89137187e-01\n",
      "  1.51660791e-01  1.51660791e-01 -8.99336682e-01 -1.28970717e+00\n",
      " -1.04947918e+00 -2.68738198e-01 -8.69308183e-01 -5.08966192e-01\n",
      "  1.51660791e-01  1.65308575e+00 -1.01945068e+00 -7.49194186e-01\n",
      " -2.85102043e-02 -1.04947918e+00  9.02373272e-01 -1.18595702e-01\n",
      " -6.89137187e-01  1.51829490e-03 -1.48624201e-01  3.01803287e-01\n",
      " -1.19962167e+00 -4.48909194e-01 -1.19962167e+00 -1.89027716e+00\n",
      " -9.89422180e-01 -2.08681200e-01 -1.34976417e+00 -5.99051690e-01\n",
      " -7.49194186e-01 -1.78652700e-01 -1.04947918e+00 -1.04947918e+00\n",
      " -2.08681200e-01 -6.29080189e-01 -2.13050515e+00 -6.89137187e-01\n",
      " -1.65004916e+00 -7.19165687e-01 -9.29365181e-01  3.01803287e-01\n",
      " -9.59393680e-01 -8.09251184e-01 -8.39279684e-01 -2.67101814e+00\n",
      " -1.04947918e+00 -8.09251184e-01 -4.48909194e-01 -1.48624201e-01\n",
      " -1.48624201e-01 -4.18880694e-01 -1.34976417e+00  3.15467941e-02\n",
      " -7.49194186e-01 -8.09251184e-01  2.71774788e-01  1.65308575e+00\n",
      "  1.35280076e+00  3.15451071e+00  4.51945783e-01 -1.04947918e+00\n",
      " -1.04947918e+00 -4.48909194e-01 -1.40982117e+00  1.05251577e+00\n",
      " -1.48624201e-01 -2.08681200e-01  1.35280076e+00  9.02373272e-01\n",
      " -4.48909194e-01 -4.48909194e-01  9.92458769e-01  1.95337074e+00\n",
      "  6.32116779e-01  1.23268676e+00 -2.98766697e-01  7.52230776e-01\n",
      "  3.61860286e-01 -4.48909194e-01 -4.48909194e-01 -1.48624201e-01\n",
      "  6.02088279e-01 -1.04947918e+00 -2.98766697e-01 -4.48909194e-01\n",
      " -5.99051690e-01 -2.98766697e-01  4.51945783e-01  1.51829490e-03\n",
      "  3.01803287e-01  7.52230776e-01 -1.48624201e-01  9.02373272e-01\n",
      " -1.48624201e-01  1.51660791e-01  1.51829490e-03  4.51945783e-01\n",
      "  1.51660791e-01  4.51945783e-01  9.02373272e-01  6.02088279e-01\n",
      "  3.91888785e-01  9.02373272e-01 -1.04947918e+00 -1.48624201e-01\n",
      "  1.51660791e-01  2.70408323e+00  2.10351324e+00  6.02088279e-01\n",
      "  4.51945783e-01  4.51945783e-01  6.02088279e-01  2.70408323e+00\n",
      "  1.50294326e+00  7.52230776e-01 -4.48909194e-01  1.51660791e-01\n",
      "  1.35280076e+00  6.02088279e-01 -5.99051690e-01 -2.98766697e-01\n",
      "  4.51945783e-01  1.65308575e+00  1.51829490e-03  1.35280076e+00\n",
      "  4.51945783e-01  1.51660791e-01  1.20265826e+00  1.51660791e-01\n",
      " -2.98766697e-01  4.51945783e-01  1.51660791e-01  6.02088279e-01\n",
      "  6.02088279e-01  6.02088279e-01  1.35280076e+00  7.52230776e-01\n",
      "  1.80322825e+00 -2.98766697e-01  1.51660791e-01  7.52230776e-01\n",
      "  1.51829490e-03  2.25365574e+00  1.65308575e+00  9.02373272e-01\n",
      "  4.51945783e-01  1.51660791e-01  7.52230776e-01 -2.98766697e-01\n",
      "  7.52230776e-01  9.02373272e-01  1.05251577e+00  1.51829490e-03\n",
      "  1.50294326e+00  1.65308575e+00 -1.48624201e-01  1.51829490e-03\n",
      "  1.51660791e-01  3.01803287e-01  1.05251577e+00  1.51660791e-01\n",
      "  1.51660791e-01  1.50294326e+00]\n",
      "==column:Magnesium===\n",
      "[ 1.91390522  0.01814502  0.08835836  0.93091845  1.28198515  0.86070511\n",
      " -0.26270834  1.49262517 -0.192495   -0.12228166  0.36921172 -0.33292168\n",
      " -0.75420173 -0.61377505  0.1585717   0.86070511  1.42241183  1.07134513\n",
      "  0.57985175  1.14155847  1.84369188  0.1585717   0.08835836 -0.33292168\n",
      " -0.26270834  1.7032652  -0.47334836 -0.40313502  0.50963841 -0.26270834\n",
      "  0.08835836  0.43942506  0.29899838  2.26497192  0.72027843  0.01814502\n",
      "  0.72027843 -0.12228166 -0.12228166  1.98411856  1.21177181 -0.68398839\n",
      "  0.08835836  0.22878504  0.50963841  0.79049177  0.1585717   0.08835836\n",
      "  0.22878504  0.57985175 -0.5435617  -0.40313502  0.79049177  1.07134513\n",
      "  1.28198515  1.14155847  1.28198515  0.1585717   0.57985175 -0.82441507\n",
      "  0.08835836  0.01814502 -0.40313502 -0.89462841  0.29899838 -0.12228166\n",
      " -1.52654847 -1.52654847  0.72027843  3.59902539  0.22878504 -0.96484175\n",
      " -0.89462841  2.75646531  0.08835836 -0.192495   -0.96484175  0.86070511\n",
      "  2.54582528  0.08835836 -0.96484175 -0.96484175 -1.52654847 -1.03505509\n",
      " -0.40313502 -0.05206832 -0.68398839 -0.82441507 -1.10526843 -2.0882552\n",
      " -1.31590845 -0.96484175 -1.38612179 -0.82441507 -0.12228166  4.37137214\n",
      "  2.4053986  -1.03505509 -0.82441507 -0.82441507 -0.192495   -0.82441507\n",
      " -0.12228166 -0.96484175 -1.03505509 -0.68398839 -1.38612179 -1.10526843\n",
      " -0.5435617  -0.40313502  0.50963841 -0.82441507  0.22878504 -0.82441507\n",
      " -1.10526843 -1.03505509 -0.96484175  0.57985175 -1.38612179 -0.89462841\n",
      " -0.26270834  1.35219849  0.1585717  -0.96484175 -1.24569511 -1.03505509\n",
      " -0.96484175 -0.5435617  -0.82441507 -1.38612179  1.56283851  0.29899838\n",
      " -0.12228166  0.43942506 -1.03505509 -0.40313502 -0.75420173 -0.26270834\n",
      " -0.82441507  0.08835836 -0.26270834 -0.75420173 -0.192495   -0.5435617\n",
      "  0.86070511  0.1585717  -1.38612179 -0.96484175 -0.5435617   0.93091845\n",
      "  1.63305186  0.86070511  1.14155847 -0.12228166  0.22878504 -0.47334836\n",
      " -0.75420173 -0.192495   -0.12228166 -0.75420173 -0.82441507  0.50963841\n",
      "  0.43942506  0.43942506 -0.68398839 -0.82441507  0.79049177 -0.82441507\n",
      "  0.36921172  0.86070511 -0.26270834 -0.96484175 -0.61377505 -0.33292168\n",
      "  0.1585717   1.42241183  1.42241183 -0.26270834]\n",
      "==column:Total_phenols===\n",
      "[ 0.80899739  0.56864766  0.80899739  2.49144552  0.80899739  1.56209322\n",
      "  0.32829793  0.48853108  0.80899739  1.09741707  1.04934713 -0.15240153\n",
      "  0.48853108  1.28969686  1.61016317  0.88911397  0.80899739  1.04934713\n",
      "  1.61016317  0.64876424  1.1294637   0.18408809  0.5045544   0.2962513\n",
      "  0.37636788  0.53660103  0.88911397  0.16806478  1.04934713  0.56864766\n",
      "  1.1294637   0.90513729  0.20011141  1.04934713  0.0879482   0.64876424\n",
      "  0.48853108  0.24818135  0.16806478  1.1294637   1.36981344  0.24818135\n",
      "  1.53004659  0.55262435  1.1294637   0.88911397  1.53004659  1.28969686\n",
      "  0.72888082  0.93718392  0.68081087  0.24818135  2.53951547  1.1294637\n",
      "  0.48853108  1.06537044  1.44993001  1.1294637   1.77039632 -0.50491447\n",
      " -0.39275127 -0.44082121 -0.31263469  1.93062948 -0.64912431  0.20011141\n",
      "  1.09741707 -0.29661137  0.37636788 -0.71321758 -1.91496624  1.04934713\n",
      " -0.66514763  1.61016317  1.73834969 -1.09777715 -0.55298442 -0.92152068\n",
      " -0.633101    0.85706734  0.20011141 -0.15240153 -0.47286784 -1.03368389\n",
      " -0.15240153 -0.15240153 -0.82538078 -0.60105437 -0.55298442 -0.15240153\n",
      " -1.11380046 -1.3541502  -1.4663134   0.24818135  1.16151034  0.32829793\n",
      " -1.11380046  0.40841451  1.96267611  0.88911397 -0.10433159 -1.3541502\n",
      "  0.42443782  0.32829793 -0.15240153 -0.98561394 -1.03368389 -1.4663134\n",
      "  0.10397151  0.7128575   1.41788338  0.40841451 -0.87345073  0.2962513\n",
      "  0.42443782  0.26420467 -0.50491447 -0.47286784 -1.06573052 -0.47286784\n",
      "  0.96923055  1.41788338 -0.15240153  0.52057772  0.90513729  0.48853108\n",
      "  0.7128575  -0.26456474 -0.1203549  -0.31263469 -1.2580103  -1.59449993\n",
      " -1.83484966 -0.95356731 -0.47286784 -1.08175383 -1.4663134  -0.80935747\n",
      " -1.08175383  0.03987825 -1.20994036 -1.43426677 -1.19391704 -0.47286784\n",
      " -1.4663134  -1.27403362 -2.10724602 -0.95356731 -0.58503105 -1.41824346\n",
      " -1.43426677 -1.30608025 -0.15240153 -0.79333415 -1.30608025 -0.88947405\n",
      " -0.79333415 -0.633101    0.80899739  0.48853108  0.00783162 -0.74526421\n",
      " -1.03368389 -1.45029009 -1.51438335 -1.62654656 -0.95356731 -1.30608025\n",
      " -1.19391704 -0.50491447 -1.67461651 -1.45029009 -0.98561394 -0.98561394\n",
      " -0.79333415 -1.12982378 -1.03368389 -0.39275127]\n",
      "==column:Flavanoids===\n",
      "[ 1.03481896e+00  7.33628941e-01  1.21553297e+00  1.46652465e+00\n",
      "  6.63351271e-01  1.36612798e+00  4.92676928e-01  4.82637261e-01\n",
      "  9.54501620e-01  1.12517596e+00  1.29585031e+00  4.02319923e-01\n",
      "  7.33628941e-01  1.66731799e+00  1.61711966e+00  8.84223950e-01\n",
      "  1.11513630e+00  1.37616764e+00  1.90827001e+00  1.00469996e+00\n",
      "  1.14525530e+00  3.82240589e-01  8.54104948e-01  3.42081920e-01\n",
      "  5.83033933e-01  6.53311604e-01  9.14342951e-01  1.61367910e-01\n",
      "  9.44461953e-01  3.01923251e-01  1.22557264e+00  1.16533463e+00\n",
      "  6.63351271e-01  7.13549607e-01  5.02716595e-01  9.54501620e-01\n",
      "  6.53311604e-01  4.02319923e-01  6.13152935e-01  1.01473962e+00\n",
      "  1.26573130e+00  6.53311604e-01  1.53680232e+00  6.03113268e-01\n",
      "  9.74580955e-01  6.23192602e-01  1.14525530e+00  1.36612798e+00\n",
      "  8.94263617e-01  1.51672298e+00  1.24565197e+00  9.64541288e-01\n",
      "  1.71751633e+00  7.63747943e-01  8.74184283e-01  7.53708276e-01\n",
      "  9.74580955e-01  1.20549330e+00  1.64723866e+00 -1.46505818e+00\n",
      " -9.42995485e-01 -6.21726134e-01 -2.40218779e-01  1.07497763e+00\n",
      " -2.80377448e-01  6.23192602e-01  1.15529496e+00 -2.93857675e-02\n",
      " -7.32162473e-01 -7.52241808e-01 -1.01327316e+00  8.34025614e-01\n",
      " -1.90020443e-01  8.64144615e-01  1.11169574e-01 -4.61091458e-01\n",
      "  7.33234123e-04 -7.12083139e-01 -1.79980776e-01  5.22795930e-01\n",
      "  2.31645580e-01  5.02716595e-01 -4.51051791e-01 -4.41012124e-01\n",
      "  1.81447244e-01 -8.96237709e-02 -3.40615451e-01 -4.20932789e-01\n",
      " -3.40615451e-01 -4.41012124e-01 -5.31369129e-01 -7.82360809e-01\n",
      " -5.71527798e-01  2.21605913e-01  2.31645580e-01  2.41685247e-01\n",
      " -1.04339216e+00  4.72597594e-01  1.72755600e+00  9.64541288e-01\n",
      "  1.41288575e-01 -6.71924470e-01  8.10505719e-02 -3.90813788e-01\n",
      " -1.09703105e-01 -1.90020443e-01  7.33234123e-04 -2.70337781e-01\n",
      "  1.07729013e-02  8.94263617e-01  5.52914931e-01  2.41685247e-01\n",
      "  7.33234123e-04 -1.93461003e-02  2.61764582e-01  1.41288575e-01\n",
      " -4.30972456e-01  6.09712375e-02 -7.82360809e-01 -3.90813788e-01\n",
      "  7.63747943e-01  3.06283174e+00  1.01129906e-01  6.23192602e-01\n",
      "  1.00469996e+00  6.23192602e-01  1.12517596e+00  2.11566246e-01\n",
      "  4.22399258e-01 -2.80377448e-01 -7.82360809e-01 -8.12479811e-01\n",
      " -9.42995485e-01 -8.32559145e-01 -1.45501851e+00 -1.37470118e+00\n",
      " -1.56545485e+00 -1.43493918e+00 -1.55541519e+00 -1.43493918e+00\n",
      " -1.53533585e+00 -1.53533585e+00 -1.51525652e+00 -1.23414583e+00\n",
      " -1.25422517e+00 -1.48513751e+00 -1.69597053e+00 -1.38474084e+00\n",
      " -1.27430450e+00 -6.41805468e-01 -4.61091458e-01 -6.71924470e-01\n",
      " -7.52241808e-01 -1.20402683e+00 -1.45501851e+00 -1.40482018e+00\n",
      " -1.20402683e+00 -1.45501851e+00 -7.22122806e-01 -9.32955818e-01\n",
      " -1.11366983e+00 -1.47509785e+00 -1.43493918e+00 -1.33454251e+00\n",
      " -1.35462184e+00 -1.56545485e+00 -1.11366983e+00 -1.37470118e+00\n",
      " -1.19398717e+00 -1.07351116e+00 -1.54537552e+00 -1.52529618e+00\n",
      " -1.33454251e+00 -1.42489951e+00 -1.28434417e+00 -1.34458217e+00\n",
      " -1.35462184e+00 -1.27430450e+00]\n",
      "==column:Nonflavanoid_phenols===\n",
      "[-0.65956311 -0.82071924 -0.49840699 -0.98187536  0.22679555 -0.17609475\n",
      " -0.49840699 -0.41782893 -0.57898505 -1.14303148 -1.14303148 -0.82071924\n",
      " -0.57898505  0.5491078  -0.57898505 -0.49840699 -0.25667281  0.30737361\n",
      " -0.33725087 -1.54592178 -0.98187536 -0.9012973  -0.74014117 -0.82071924\n",
      " -0.65956311  0.87142004 -0.17609475 -0.74014117  0.06563943 -0.82071924\n",
      " -0.57898505 -1.14303148  0.46852973  1.11315422 -0.57898505 -0.82071924\n",
      " -0.17609475 -0.57898505 -0.65956311 -1.3041876  -0.17609475 -0.74014117\n",
      " -1.54592178 -0.33725087 -0.65956311 -0.49840699 -0.74014117 -1.22360954\n",
      " -0.33725087 -0.33725087 -1.54592178 -1.14303148 -0.33725087  0.22679555\n",
      " -1.22360954 -1.3041876  -0.82071924 -0.41782893 -1.38476566 -0.65956311\n",
      "  2.16066901  1.3548884  -0.33725087 -1.38476566  0.71026392  0.06563943\n",
      " -0.82071924 -0.74014117  1.51604452 -1.78765596  0.06563943 -1.22360954\n",
      " -0.74014117 -1.22360954 -1.86823402 -0.17609475 -0.98187536  0.5491078\n",
      " -0.09551669  0.5491078  -0.49840699 -0.82071924  0.30737361  1.99951289\n",
      " -1.14303148 -0.49840699  0.5491078   0.30737361  0.9519981   0.46852973\n",
      "  1.27431034  1.11315422  1.7577787  -0.9012973  -1.54592178 -0.33725087\n",
      " -1.78765596 -0.57898505 -0.98187536  0.71026392 -0.82071924 -0.57898505\n",
      " -0.17609475  0.06563943 -0.33725087  2.40240319  0.06563943  0.9519981\n",
      "  0.22679555 -0.57898505 -0.98187536 -0.82071924  1.91893483  0.46852973\n",
      "  0.5491078   1.27431034 -0.49840699 -0.17609475  0.5491078   0.06563943\n",
      " -0.33725087  0.87142004  0.5491078  -0.49840699 -1.22360954  0.06563943\n",
      "  0.22679555  1.7577787   0.30737361  0.46852973 -1.22360954 -0.98187536\n",
      " -0.74014117 -1.54592178  1.91893483  2.16066901  1.3548884   2.16066901\n",
      "  1.7577787   1.3548884   1.3548884   0.06563943  1.11315422  0.87142004\n",
      " -0.57898505  0.5491078   0.30737361  0.87142004  0.71026392 -0.17609475\n",
      " -1.14303148 -0.98187536 -0.82071924  1.99951289  1.3548884   1.99951289\n",
      "  0.9519981   2.16066901  1.3548884   1.27431034  1.11315422  1.11315422\n",
      "  1.91893483  0.30737361  0.38795167  1.27431034  0.5491078   0.30737361\n",
      "  0.22679555 -0.74014117  0.30737361  0.9519981   0.62968586  1.27431034\n",
      "  0.5491078   0.5491078   1.3548884   1.59662258]\n",
      "==column:Proanthocyanins===\n",
      "[ 1.22488398 -0.54472099  2.13596773  1.03215473  0.40140444  0.66421706\n",
      "  0.6817379  -0.59728351  0.6817379   0.45396697  1.38257156 -0.03661659\n",
      "  0.3838836   2.13596773  2.39878035 -0.22934584  0.66421706  0.22619603\n",
      "  0.47148781  0.12107098  0.891988    0.6817379   0.17363351 -0.22934584\n",
      "  0.12107098  0.57661286 -0.24686669 -0.4220751   0.2962794   0.6817379\n",
      "  1.38257156  0.62917538  0.66421706 -0.4220751  -0.08917911  0.47148781\n",
      " -0.40455426 -0.26438753 -0.38703342  0.85694632  1.31248819 -0.19430416\n",
      "  0.19115435  0.12107098  0.76934211 -0.59728351  1.04967557  0.96207136\n",
      "  1.38257156  0.85694632  2.31117614  1.22488398  0.48900865  0.15611266\n",
      "  0.05098762  1.50521744  0.76934211  0.12107098  0.78686295 -2.05151334\n",
      " -2.06903418 -1.70109651 -1.50836726  0.48900865 -0.98274202  0.85694632\n",
      "  1.20736314 -0.96522118 -2.05151334  1.59282165 -0.22934584  0.48900865\n",
      " -0.98274202  0.64669622  0.10355014 -0.77249192 -0.22934584 -1.12290875\n",
      "  2.04836353  0.62917538 -0.28190837  0.31380024 -0.33447089  0.05098762\n",
      "  1.33000903 -0.22934584 -0.05413743 -0.43959594 -0.4220751  -0.36951257\n",
      "  0.0860293   0.06850846  0.05098762  0.69925874 -0.4220751   2.95944727\n",
      " -0.05413743  0.31380024  0.62917538  2.13596773 -0.33447089 -0.4220751\n",
      " -0.49215846 -0.29942921 -0.19430416 -0.29942921  0.06850846  0.06850846\n",
      "  0.85694632  1.57530081  3.48507251 -0.64984604 -0.94770034 -0.26438753\n",
      " -0.96522118  0.73430043 -0.10669995  0.03346678 -1.33315885  0.48900865\n",
      "  0.41892528  0.48900865  0.20867519  0.73430043  2.31117614 -0.4220751\n",
      "  0.31380024  0.2962794   0.54157117 -0.4220751  -1.14042959 -1.33315885\n",
      " -1.33315885 -1.315638   -0.59728351 -1.14042959 -1.38572137 -0.86009613\n",
      " -1.24555464 -1.36820053 -1.47332558 -1.66605483 -1.8237424  -1.00026286\n",
      " -0.79001277 -0.5096793  -1.59597147 -1.28059632 -0.59728351 -0.79001277\n",
      " -0.59728351 -0.57976267 -0.05413743  0.48900865 -0.33447089 -0.07165827\n",
      " -0.05413743 -0.79001277  1.94323848  1.22488398 -0.96522118 -1.38572137\n",
      " -1.10538791 -1.14042959 -0.98274202 -0.77249192 -0.22934584 -1.08786707\n",
      " -0.08917911 -0.84257529 -1.50836726 -1.66605483 -0.61480435 -0.9301795\n",
      " -0.31695005 -0.4220751  -0.22934584 -0.4220751 ]\n",
      "==column:Color_intensity===\n",
      "[ 0.25171685 -0.29332133  0.26901965  1.18606801 -0.31927553  0.73186953\n",
      "  0.08301456 -0.00349944  0.06138606  0.93517742  0.29929955 -0.02512794\n",
      "  0.23441405  0.14790005  1.05629702  0.96978302  0.49395604  0.66698403\n",
      "  1.575381    0.01812906  0.25604255 -0.24141293 -0.54421192 -0.48797782\n",
      " -0.66533151 -0.63937732 -0.11164194 -0.47932642 -0.24141293 -0.15489893\n",
      "  0.27767105  0.79675503 -0.52690912  0.14790005 -0.37118393  0.01812906\n",
      " -0.19815593 -0.34955543 -0.58746892  0.01812906  0.46367614 -0.33657833\n",
      "  0.16087715 -0.30197273 -0.00782514  0.07868886 -0.06838494  0.45069904\n",
      "  0.49395604  1.66189499  0.92652602  0.23441405  0.86164053  0.53721304\n",
      "  0.34255655  0.51558454  0.57181864  0.40744204  0.75349803 -1.34446639\n",
      " -0.77347401  0.29929955 -0.54421192 -0.26304143 -0.9118964  -0.19815593\n",
      "  0.10464306 -0.16355033 -0.81673101 -0.9551534  -0.86863941 -0.72589131\n",
      " -0.57016612 -0.73886841 -0.79942821 -0.54421192 -0.19815593 -1.0416674\n",
      " -0.71723991 -1.076273   -1.1065529  -0.50095492 -1.23632389 -0.11164194\n",
      " -0.86863941 -1.0546445  -1.1281814  -1.0632959  -0.9767819  -1.43530608\n",
      " -1.14980989 -0.63072592 -0.86863941 -1.25795239 -0.78212541 -1.0632959\n",
      " -1.1065529  -0.9335249  -0.24141293 -1.19306689 -0.76049691 -1.1281814\n",
      " -0.9767819  -1.29688369 -0.9162221  -1.0200389  -0.71723991 -0.76049691\n",
      " -1.0200389  -1.0416674  -0.9335249  -1.32283789 -0.54421192 -0.85566231\n",
      " -0.9335249  -1.36609489 -1.34446639 -1.29688369 -0.71723991 -1.63428828\n",
      " -0.78212541  0.40744204 -1.28823229 -1.0632959  -0.9767819  -0.9940847\n",
      " -0.48365212 -0.89026791 -1.27092949 -1.0632959  -0.41444092  0.14790005\n",
      "  0.27767105 -0.02512794  0.16952855  0.88326902 -0.52258342 -0.02512794\n",
      "  0.27767105 -0.05973354 -0.19815593  0.23441405 -0.30629843 -0.28466993\n",
      "  1.36342171 -0.45769792 -0.06838494  1.12118252  1.4542614   1.87817999\n",
      "  1.532124    2.48377796  0.88326902  2.36265837  1.09955402  1.22932501\n",
      "  1.70947769  1.05629702  3.43543192  2.89471945  1.12118252  0.35553365\n",
      "  0.22576265  0.09599166  1.95604258  0.67563543  2.43186956  2.25019017\n",
      "  1.5580782   1.488867    0.19115705  2.09446454  2.00795098  1.14281101\n",
      "  0.96978302  2.22423597  1.83492299  1.79166599]\n",
      "==column:Hue===\n",
      "[ 0.36217728  0.40605066  0.31830389 -0.42754369  0.36217728  0.40605066\n",
      "  0.2744305   0.44992405  0.53767082  0.23055711  1.28351841  0.93253131\n",
      "  0.84478453  1.28351841  1.06415147  1.41513857  0.49379744  0.75703776\n",
      "  1.19577163  0.01119018  0.58154421  0.31830389  0.66929099  0.58154421\n",
      "  0.71316437  0.75703776 -0.16430337  0.2744305   1.28351841  0.36217728\n",
      "  1.02027808  0.58154421  1.19577163  1.28351841  0.6254176   0.36217728\n",
      "  0.58154421  0.71316437  0.9764047  -0.29592353 -0.03268321 -0.20817676\n",
      " -0.33979692 -0.60303724 -0.33979692 -0.38367031  0.36217728 -0.20817676\n",
      "  0.49379744  0.71316437  0.71316437  1.23964502  0.23055711  0.75703776\n",
      " -0.16430337  0.09893695 -0.0765566   0.49379744 -0.29592353  0.40605066\n",
      "  1.28351841  0.09893695  1.19577163  1.15189824  2.16098615  1.02027808\n",
      "  0.71316437  0.71316437  0.2744305   1.41513857 -0.22572611  1.76612566\n",
      "  0.09893695  1.54675873  0.14281034  1.19577163  1.02027808  0.01119018\n",
      "  0.44992405  1.02027808  1.85387244  0.88865792  1.54675873 -0.51529047\n",
      " -0.7346574   1.19577163  1.6345055   1.76612566  0.18668373  0.49379744\n",
      "  0.53767082  0.40605066  0.01119018  0.84478453  0.88865792  0.88865792\n",
      " -0.03268321  1.19577163  0.36217728  2.02936599  1.37126518  0.36217728\n",
      " -0.69078402 -0.0765566   0.36217728 -0.42754369  0.18668373 -0.33979692\n",
      " -0.42754369  0.01119018 -0.91015095 -0.25205014  1.19577163  0.6254176\n",
      " -0.12042998  3.30169422 -0.03268321  0.44992405 -1.12951789 -0.12042998\n",
      " -0.69078402 -0.12042998 -0.16430337 -0.99789773 -0.91015095 -0.42754369\n",
      " -1.17339127  0.05506357 -0.29592353 -0.7346574  -0.86627756 -0.95402434\n",
      " -1.30501144 -0.77853079 -0.91015095 -0.99789773 -0.91015095 -0.60303724\n",
      " -0.64691063 -0.29592353 -0.82240418 -1.12951789 -0.29592353 -0.20817676\n",
      " -1.34888482 -1.56825176 -1.65599853 -1.83149208 -1.78761869 -1.69987192\n",
      " -1.61212515 -2.09473241 -1.52437837 -1.74374531 -1.65599853 -1.56825176\n",
      " -1.69987192 -1.26113805 -1.69987192 -1.69987192 -1.74374531  0.01119018\n",
      " -0.38367031 -1.21726466 -1.12951789 -0.77853079 -0.47141708 -1.04177111\n",
      " -0.95402434 -1.26113805 -1.30501144 -1.69987192 -1.48050498 -1.39275821\n",
      " -1.12951789 -1.61212515 -1.56825176 -1.52437837]\n",
      "==column:OD280/OD315_of_diluted_wines===\n",
      "[ 1.84791957  1.1134493   0.78858745  1.18407144  0.44960118  0.33660575\n",
      "  1.36768901  1.36768901  0.33660575  1.32531572  0.78858745  0.29423247\n",
      "  0.40722789  0.16711262  0.54847218  0.37897904  0.05411719 -0.05887823\n",
      "  0.29423247  1.05695159  1.55130658  1.28294244  1.96091499  1.43831115\n",
      "  1.70667528  0.83096074  0.8592096   0.22361033  1.1134493   1.38181344\n",
      "  0.13886376  0.37897904  0.36485461  0.54847218  0.36485461  1.2123203\n",
      "  0.23773476 -0.1436248   0.1106149   1.29706687  1.08520045  0.54847218\n",
      "  1.33944015  0.54847218  1.04282716  1.01457831  1.16994702  1.01457831\n",
      "  0.19536147  0.68971646  0.42135232  1.07107602  0.91570731  0.44960118\n",
      "  0.83096074  0.59084546  0.98632945  0.32248133  0.36485461 -1.11821035\n",
      " -1.33007677 -1.44307219 -0.21424694  0.36485461 -0.53910879 -0.44023779\n",
      "  0.80271188  1.22644473 -0.96284164  0.64734317 -1.11821035  0.77446303\n",
      "  0.23773476  1.25469358  0.73208974 -0.66622864 -0.18599809 -0.12950037\n",
      " -0.42611337  0.73208974  0.71796531  0.74621417  0.15298819 -0.84984621\n",
      "  0.6614676   0.77446303 -0.49673551  0.84508517  0.19536147  0.84508517\n",
      " -0.48261108  0.05411719 -0.77922407  0.97220502  0.49197446  0.02586833\n",
      " -0.49673551  0.18123704  0.22361033  0.3083569   0.49197446  0.22361033\n",
      "  1.08520045 -0.2424958   1.35356458  0.97220502  0.78858745 -0.27074466\n",
      "  0.57672103  0.91570731  0.28010804  0.23773476 -0.15774923 -0.42611337\n",
      "  0.81683631  0.36485461  1.01457831  0.49197446 -0.6944775   0.61909432\n",
      "  1.09932487  1.52305772  0.71796531  0.68971646  1.45243558  0.94395616\n",
      "  0.32248133 -0.2424958   0.23773476 -0.05887823 -1.86680504 -1.68318747\n",
      " -1.76793404 -1.86680504 -1.55606762 -1.45719662 -1.89505389 -1.30182791\n",
      " -1.11821035 -0.65210422 -0.42611337 -0.20012252 -0.77922407 -0.7933485\n",
      " -0.86397064 -1.31595234 -1.81030733 -1.06171263 -1.40069891 -1.81030733\n",
      " -1.85268061 -1.61256533 -1.81030733 -1.55606762 -1.49956991 -1.5984409\n",
      " -1.37245005 -1.2453302  -0.92046835 -1.17470806 -1.45719662 -1.11821035\n",
      " -0.70860193 -1.21708134 -1.31595234 -1.21708134 -1.48544548 -1.21708134\n",
      " -1.1464592  -0.97696606 -1.10408592 -1.38657448 -1.27357906 -1.23120577\n",
      " -1.48544548 -1.48544548 -1.40069891 -1.42894777]\n",
      "==column:Proline===\n",
      "[ 1.01300893  0.96524152  1.39514818  2.33457383 -0.03787401  2.23903902\n",
      "  1.72952002  1.74544249  0.94931905  0.94931905  2.43010864  1.69767508\n",
      "  1.82505483  1.28369089  2.54793491  1.79320989  1.69767508  1.22000102\n",
      "  2.97147258  0.3124203   0.10542821  0.07358327  0.91747411  0.85378424\n",
      "  0.3124203   0.2646529   1.42699311  1.71359755  0.53533487  0.91747411\n",
      "  1.71359755  2.44603111  0.7741719   1.55437286  1.10854374  0.55125733\n",
      "  0.42387759  1.14038868  0.86970671  0.04173834  0.15319562  0.91747411\n",
      "  1.10854374 -0.21302116  0.43980005  1.06077633  1.01300893  0.75824943\n",
      "  0.99708646  1.63398521  1.28369089  1.64990767  1.41107064  2.00020199\n",
      "  0.99708646  1.18815608  0.71048202  1.66583014  1.71359755 -0.72254016\n",
      " -0.21302116 -0.94545472 -0.37224585 -1.04098953 -1.24798163 -0.21939015\n",
      " -0.77986105 -0.7543851   0.0098934  -0.0920104   0.39203265 -1.07283447\n",
      " -0.87539586  0.75824943  0.44298455 -1.01551358 -1.13015536 -0.78623004\n",
      "  0.0098934  -0.9040563  -1.49318765 -0.10474838 -0.37224585 -0.73846263\n",
      " -0.72254016 -0.94545472 -0.8021525  -0.58879142 -0.21302116 -0.38816832\n",
      " -0.84991991 -0.94545472 -0.8021525  -1.45497372 -1.27982657  0.60539373\n",
      " -0.38816832 -1.01551358 -0.27671104 -1.08557245 -0.11748635 -0.58879142\n",
      " -0.98366865 -1.056912   -0.23849711 -1.37536138 -0.7543851  -0.82444396\n",
      " -1.38491486 -0.21302116 -0.58879142 -1.34351644 -0.44548921 -0.99640662\n",
      " -1.15244682 -1.08238795 -0.8021525  -1.27982657 -1.19384523 -0.58242244\n",
      " -0.38816832 -0.89768732 -1.21613669 -1.16836928 -1.16836928 -1.17473827\n",
      " -1.25753511 -0.89450282 -1.28938005 -0.53147054 -0.37224585 -0.69069522\n",
      " -0.59516041 -0.46778066 -0.30855597 -0.16525376 -0.08564141 -0.73846263\n",
      " -0.53147054 -0.4996256  -0.46778066  0.10542821 -0.72254016 -0.62700535\n",
      "  0.34426524  0.2646529  -1.056912   -0.38816832 -0.30855597 -0.62700535\n",
      " -0.78623004 -0.84991991 -1.02506707 -0.22894363 -0.34040091 -0.06971894\n",
      " -0.84991991  0.42387759 -0.27671104 -0.40409079 -0.72254016 -0.21302116\n",
      " -0.56331547 -0.22894363 -0.42001326 -0.72254016 -0.16525376 -0.19709869\n",
      "  0.0098934  -0.37224585 -0.7543851  -0.88176485 -0.27671104 -0.02195154\n",
      "  0.0098934   0.28057537  0.29649784 -0.59516041]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 14):\n",
    "    print(\"==column:{}===\".format(columns[i]))\n",
    "    print(zscore(data_set_np[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C\n",
    "The experiment want to try: is there any relation between alcohol and color intensity, first will try a linear regression.\n",
    "Use alcohol as features to get values of color intesity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_np = data_set_np[:, alcohol_col]\n",
    "color_np = data_set_np[:, color_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "print(alcohol_np.size)\n",
    "print(color_np.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = alcohol_np.size\n",
    "indices = np.random.randint(0, n, n*80//100)\n",
    "\n",
    "x_train = alcohol_np[indices]\n",
    "y_train = color_np[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.72 12.17 13.52 13.16 12.22 11.79 14.1  14.38 13.48 13.49 13.51 11.87\n",
      " 14.06 12.85 13.71 12.93 13.67 12.33 12.   12.25 13.87 12.93 13.75 13.5\n",
      " 12.25 12.77 14.19 13.29 14.22 13.32 11.66 13.05 13.29 13.83 12.37 14.23\n",
      " 13.4  12.25 14.16 13.17 13.05 13.56 12.08 13.17 12.33 13.69 12.99 13.16\n",
      " 12.72 14.22 13.29 13.69 13.62 12.69 12.37 13.58 14.38 12.33 13.5  14.06\n",
      " 13.05 12.33 11.87 12.51 13.5  13.71 12.6  12.04 12.07 13.28 14.3  12.87\n",
      " 12.77 12.29 13.49 11.96 13.72 11.87 13.11 12.51 13.62 13.58 11.96 12.85\n",
      " 12.93 13.9  12.37 12.34 13.86 11.41 11.76 12.29 11.79 13.9  12.04 14.06\n",
      " 13.45 13.34 13.05 12.25 12.37 13.39 14.21 14.19 13.87 11.87 13.03 11.84\n",
      " 12.25 12.85 12.08 12.52 13.17 11.65 11.81 14.12 13.73 14.75 13.73 12.45\n",
      " 13.52 13.52 12.34 13.88 12.33 12.25 12.88 13.23 13.68 14.75 13.83 11.84\n",
      " 12.93 12.37 13.24 12.08 12.67 12.04 11.82 12.25 13.05 13.51]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = []\n",
    "for i in range(n):\n",
    "    if not (i in indices):\n",
    "        test_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:6: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f952be43da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import arange,array,ones,linalg\n",
    "from pylab import plot,show\n",
    "\n",
    "A = array([ x_train, ones(n*80//100)])\n",
    "y = y_train\n",
    "w = linalg.lstsq(A.T,y_train)[0] # obtaining the parameters\n",
    "\n",
    "# plotting the line\n",
    "line = w[0]*x_train+w[1] # regression line\n",
    "plot(x_train,line,'r-',x_train,y,'o')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(test_indices))\n",
    "# https://github.com/peter6888/cs224n/blob/master/Tensorflow_LiveDemo/LinearRegression_Tf.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.estimator package not installed.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'app'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0a26d69415f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# init and imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TKAgg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tf.estimator package not installed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'app'"
     ]
    }
   ],
   "source": [
    "# init and imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use('TKAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression():\n",
    "    x = tf.placeholder(tf.float32, shape=(None,), name='x')\n",
    "    y = tf.placeholder(tf.float32, shape=(None,), name='y')\n",
    "    \n",
    "    with tf.variable_scope('lreg') as scope:\n",
    "        w = tf.Variable(np.random.normal(), name='W')\n",
    "        y_pred = tf.multiply(w,x)\n",
    "        loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "    return x, y, y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate linear data\n",
    "def generate_dataset():\n",
    "    x_batch = x_train #data_set_np[:, [0,alcohol_col]] #\n",
    "    y_batch = y_train # data_set_np[:, color_col] #y_train\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    x_batch, y_batch = generate_dataset()\n",
    "    \n",
    "    # demo code here\n",
    "    x, y, y_pred, loss = linear_regression()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as session:\n",
    "        session.run(init)\n",
    "        \n",
    "        feed_dict = {x: x_batch, y:y_batch}\n",
    "        \n",
    "        for _ in range(300):\n",
    "            loss_val, _ = session.run([loss, optimizer], feed_dict)\n",
    "            print('loss:', loss_val.mean())\n",
    "            \n",
    "        y_pred_batch = session.run(y_pred, {x: x_batch})\n",
    "   \n",
    "    plt.figure(1)\n",
    "    plt.scatter(x_batch, y_batch)\n",
    "    plt.plot(x_batch, y_pred_batch)\n",
    "    plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 160.696\n",
      "loss: 150.341\n",
      "loss: 140.673\n",
      "loss: 131.649\n",
      "loss: 123.224\n",
      "loss: 115.359\n",
      "loss: 108.017\n",
      "loss: 101.163\n",
      "loss: 94.7647\n",
      "loss: 88.7915\n",
      "loss: 83.2155\n",
      "loss: 78.01\n",
      "loss: 73.1506\n",
      "loss: 68.6142\n",
      "loss: 64.3793\n",
      "loss: 60.426\n",
      "loss: 56.7354\n",
      "loss: 53.2901\n",
      "loss: 50.0738\n",
      "loss: 47.0713\n",
      "loss: 44.2684\n",
      "loss: 41.6518\n",
      "loss: 39.2092\n",
      "loss: 36.9289\n",
      "loss: 34.8001\n",
      "loss: 32.8129\n",
      "loss: 30.9578\n",
      "loss: 29.226\n",
      "loss: 27.6093\n",
      "loss: 26.1\n",
      "loss: 24.6911\n",
      "loss: 23.3758\n",
      "loss: 22.148\n",
      "loss: 21.0017\n",
      "loss: 19.9317\n",
      "loss: 18.9328\n",
      "loss: 18.0003\n",
      "loss: 17.1297\n",
      "loss: 16.3171\n",
      "loss: 15.5584\n",
      "loss: 14.8502\n",
      "loss: 14.1891\n",
      "loss: 13.5719\n",
      "loss: 12.9957\n",
      "loss: 12.4578\n",
      "loss: 11.9557\n",
      "loss: 11.487\n",
      "loss: 11.0494\n",
      "loss: 10.6409\n",
      "loss: 10.2595\n",
      "loss: 9.90354\n",
      "loss: 9.57121\n",
      "loss: 9.26097\n",
      "loss: 8.97134\n",
      "loss: 8.70098\n",
      "loss: 8.44858\n",
      "loss: 8.21296\n",
      "loss: 7.993\n",
      "loss: 7.78766\n",
      "loss: 7.59597\n",
      "loss: 7.41702\n",
      "loss: 7.24997\n",
      "loss: 7.09402\n",
      "loss: 6.94844\n",
      "loss: 6.81253\n",
      "loss: 6.68566\n",
      "loss: 6.56722\n",
      "loss: 6.45666\n",
      "loss: 6.35344\n",
      "loss: 6.25708\n",
      "loss: 6.16713\n",
      "loss: 6.08316\n",
      "loss: 6.00477\n",
      "loss: 5.93159\n",
      "loss: 5.86328\n",
      "loss: 5.7995\n",
      "loss: 5.73997\n",
      "loss: 5.68439\n",
      "loss: 5.6325\n",
      "loss: 5.58407\n",
      "loss: 5.53886\n",
      "loss: 5.49665\n",
      "loss: 5.45724\n",
      "loss: 5.42046\n",
      "loss: 5.38612\n",
      "loss: 5.35406\n",
      "loss: 5.32413\n",
      "loss: 5.2962\n",
      "loss: 5.27012\n",
      "loss: 5.24577\n",
      "loss: 5.22304\n",
      "loss: 5.20183\n",
      "loss: 5.18202\n",
      "loss: 5.16353\n",
      "loss: 5.14627\n",
      "loss: 5.13015\n",
      "loss: 5.11511\n",
      "loss: 5.10107\n",
      "loss: 5.08796\n",
      "loss: 5.07572\n",
      "loss: 5.06429\n",
      "loss: 5.05363\n",
      "loss: 5.04367\n",
      "loss: 5.03438\n",
      "loss: 5.0257\n",
      "loss: 5.0176\n",
      "loss: 5.01004\n",
      "loss: 5.00298\n",
      "loss: 4.99639\n",
      "loss: 4.99024\n",
      "loss: 4.9845\n",
      "loss: 4.97913\n",
      "loss: 4.97413\n",
      "loss: 4.96946\n",
      "loss: 4.9651\n",
      "loss: 4.96102\n",
      "loss: 4.95722\n",
      "loss: 4.95368\n",
      "loss: 4.95036\n",
      "loss: 4.94727\n",
      "loss: 4.94438\n",
      "loss: 4.94169\n",
      "loss: 4.93917\n",
      "loss: 4.93683\n",
      "loss: 4.93463\n",
      "loss: 4.93259\n",
      "loss: 4.93068\n",
      "loss: 4.92889\n",
      "loss: 4.92723\n",
      "loss: 4.92567\n",
      "loss: 4.92422\n",
      "loss: 4.92287\n",
      "loss: 4.9216\n",
      "loss: 4.92042\n",
      "loss: 4.91932\n",
      "loss: 4.91829\n",
      "loss: 4.91733\n",
      "loss: 4.91643\n",
      "loss: 4.9156\n",
      "loss: 4.91482\n",
      "loss: 4.91409\n",
      "loss: 4.91341\n",
      "loss: 4.91277\n",
      "loss: 4.91218\n",
      "loss: 4.91162\n",
      "loss: 4.91111\n",
      "loss: 4.91062\n",
      "loss: 4.91017\n",
      "loss: 4.90975\n",
      "loss: 4.90936\n",
      "loss: 4.90899\n",
      "loss: 4.90865\n",
      "loss: 4.90833\n",
      "loss: 4.90803\n",
      "loss: 4.90775\n",
      "loss: 4.90749\n",
      "loss: 4.90725\n",
      "loss: 4.90702\n",
      "loss: 4.90681\n",
      "loss: 4.90661\n",
      "loss: 4.90643\n",
      "loss: 4.90626\n",
      "loss: 4.9061\n",
      "loss: 4.90595\n",
      "loss: 4.90581\n",
      "loss: 4.90568\n",
      "loss: 4.90556\n",
      "loss: 4.90544\n",
      "loss: 4.90534\n",
      "loss: 4.90524\n",
      "loss: 4.90514\n",
      "loss: 4.90506\n",
      "loss: 4.90498\n",
      "loss: 4.9049\n",
      "loss: 4.90483\n",
      "loss: 4.90477\n",
      "loss: 4.9047\n",
      "loss: 4.90465\n",
      "loss: 4.90459\n",
      "loss: 4.90454\n",
      "loss: 4.9045\n",
      "loss: 4.90445\n",
      "loss: 4.90441\n",
      "loss: 4.90437\n",
      "loss: 4.90434\n",
      "loss: 4.90431\n",
      "loss: 4.90428\n",
      "loss: 4.90425\n",
      "loss: 4.90422\n",
      "loss: 4.90419\n",
      "loss: 4.90417\n",
      "loss: 4.90415\n",
      "loss: 4.90413\n",
      "loss: 4.90411\n",
      "loss: 4.90409\n",
      "loss: 4.90408\n",
      "loss: 4.90406\n",
      "loss: 4.90405\n",
      "loss: 4.90403\n",
      "loss: 4.90402\n",
      "loss: 4.90401\n",
      "loss: 4.904\n",
      "loss: 4.90399\n",
      "loss: 4.90398\n",
      "loss: 4.90397\n",
      "loss: 4.90396\n",
      "loss: 4.90395\n",
      "loss: 4.90394\n",
      "loss: 4.90394\n",
      "loss: 4.90393\n",
      "loss: 4.90393\n",
      "loss: 4.90392\n",
      "loss: 4.90392\n",
      "loss: 4.90391\n",
      "loss: 4.90391\n",
      "loss: 4.9039\n",
      "loss: 4.9039\n",
      "loss: 4.90389\n",
      "loss: 4.90389\n",
      "loss: 4.90389\n",
      "loss: 4.90388\n",
      "loss: 4.90388\n",
      "loss: 4.90388\n",
      "loss: 4.90388\n",
      "loss: 4.90387\n",
      "loss: 4.90387\n",
      "loss: 4.90387\n",
      "loss: 4.90387\n",
      "loss: 4.90387\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90386\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90385\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n",
      "loss: 4.90384\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,  14.23],\n",
       "       [  1.  ,  13.2 ],\n",
       "       [  1.  ,  13.16],\n",
       "       [  1.  ,  14.37],\n",
       "       [  1.  ,  13.24],\n",
       "       [  1.  ,  14.2 ],\n",
       "       [  1.  ,  14.39],\n",
       "       [  1.  ,  14.06],\n",
       "       [  1.  ,  14.83],\n",
       "       [  1.  ,  13.86],\n",
       "       [  1.  ,  14.1 ],\n",
       "       [  1.  ,  14.12],\n",
       "       [  1.  ,  13.75],\n",
       "       [  1.  ,  14.75],\n",
       "       [  1.  ,  14.38],\n",
       "       [  1.  ,  13.63],\n",
       "       [  1.  ,  14.3 ],\n",
       "       [  1.  ,  13.83],\n",
       "       [  1.  ,  14.19],\n",
       "       [  1.  ,  13.64],\n",
       "       [  1.  ,  14.06],\n",
       "       [  1.  ,  12.93],\n",
       "       [  1.  ,  13.71],\n",
       "       [  1.  ,  12.85],\n",
       "       [  1.  ,  13.5 ],\n",
       "       [  1.  ,  13.05],\n",
       "       [  1.  ,  13.39],\n",
       "       [  1.  ,  13.3 ],\n",
       "       [  1.  ,  13.87],\n",
       "       [  1.  ,  14.02],\n",
       "       [  1.  ,  13.73],\n",
       "       [  1.  ,  13.58],\n",
       "       [  1.  ,  13.68],\n",
       "       [  1.  ,  13.76],\n",
       "       [  1.  ,  13.51],\n",
       "       [  1.  ,  13.48],\n",
       "       [  1.  ,  13.28],\n",
       "       [  1.  ,  13.05],\n",
       "       [  1.  ,  13.07],\n",
       "       [  1.  ,  14.22],\n",
       "       [  1.  ,  13.56],\n",
       "       [  1.  ,  13.41],\n",
       "       [  1.  ,  13.88],\n",
       "       [  1.  ,  13.24],\n",
       "       [  1.  ,  13.05],\n",
       "       [  1.  ,  14.21],\n",
       "       [  1.  ,  14.38],\n",
       "       [  1.  ,  13.9 ],\n",
       "       [  1.  ,  14.1 ],\n",
       "       [  1.  ,  13.94],\n",
       "       [  1.  ,  13.05],\n",
       "       [  1.  ,  13.83],\n",
       "       [  1.  ,  13.82],\n",
       "       [  1.  ,  13.77],\n",
       "       [  1.  ,  13.74],\n",
       "       [  1.  ,  13.56],\n",
       "       [  1.  ,  14.22],\n",
       "       [  1.  ,  13.29],\n",
       "       [  1.  ,  13.72],\n",
       "       [  2.  ,  12.37],\n",
       "       [  2.  ,  12.33],\n",
       "       [  2.  ,  12.64],\n",
       "       [  2.  ,  13.67],\n",
       "       [  2.  ,  12.37],\n",
       "       [  2.  ,  12.17],\n",
       "       [  2.  ,  12.37],\n",
       "       [  2.  ,  13.11],\n",
       "       [  2.  ,  12.37],\n",
       "       [  2.  ,  13.34],\n",
       "       [  2.  ,  12.21],\n",
       "       [  2.  ,  12.29],\n",
       "       [  2.  ,  13.86],\n",
       "       [  2.  ,  13.49],\n",
       "       [  2.  ,  12.99],\n",
       "       [  2.  ,  11.96],\n",
       "       [  2.  ,  11.66],\n",
       "       [  2.  ,  13.03],\n",
       "       [  2.  ,  11.84],\n",
       "       [  2.  ,  12.33],\n",
       "       [  2.  ,  12.7 ],\n",
       "       [  2.  ,  12.  ],\n",
       "       [  2.  ,  12.72],\n",
       "       [  2.  ,  12.08],\n",
       "       [  2.  ,  13.05],\n",
       "       [  2.  ,  11.84],\n",
       "       [  2.  ,  12.67],\n",
       "       [  2.  ,  12.16],\n",
       "       [  2.  ,  11.65],\n",
       "       [  2.  ,  11.64],\n",
       "       [  2.  ,  12.08],\n",
       "       [  2.  ,  12.08],\n",
       "       [  2.  ,  12.  ],\n",
       "       [  2.  ,  12.69],\n",
       "       [  2.  ,  12.29],\n",
       "       [  2.  ,  11.62],\n",
       "       [  2.  ,  12.47],\n",
       "       [  2.  ,  11.81],\n",
       "       [  2.  ,  12.29],\n",
       "       [  2.  ,  12.37],\n",
       "       [  2.  ,  12.29],\n",
       "       [  2.  ,  12.08],\n",
       "       [  2.  ,  12.6 ],\n",
       "       [  2.  ,  12.34],\n",
       "       [  2.  ,  11.82],\n",
       "       [  2.  ,  12.51],\n",
       "       [  2.  ,  12.42],\n",
       "       [  2.  ,  12.25],\n",
       "       [  2.  ,  12.72],\n",
       "       [  2.  ,  12.22],\n",
       "       [  2.  ,  11.61],\n",
       "       [  2.  ,  11.46],\n",
       "       [  2.  ,  12.52],\n",
       "       [  2.  ,  11.76],\n",
       "       [  2.  ,  11.41],\n",
       "       [  2.  ,  12.08],\n",
       "       [  2.  ,  11.03],\n",
       "       [  2.  ,  11.82],\n",
       "       [  2.  ,  12.42],\n",
       "       [  2.  ,  12.77],\n",
       "       [  2.  ,  12.  ],\n",
       "       [  2.  ,  11.45],\n",
       "       [  2.  ,  11.56],\n",
       "       [  2.  ,  12.42],\n",
       "       [  2.  ,  13.05],\n",
       "       [  2.  ,  11.87],\n",
       "       [  2.  ,  12.07],\n",
       "       [  2.  ,  12.43],\n",
       "       [  2.  ,  11.79],\n",
       "       [  2.  ,  12.37],\n",
       "       [  2.  ,  12.04],\n",
       "       [  3.  ,  12.86],\n",
       "       [  3.  ,  12.88],\n",
       "       [  3.  ,  12.81],\n",
       "       [  3.  ,  12.7 ],\n",
       "       [  3.  ,  12.51],\n",
       "       [  3.  ,  12.6 ],\n",
       "       [  3.  ,  12.25],\n",
       "       [  3.  ,  12.53],\n",
       "       [  3.  ,  13.49],\n",
       "       [  3.  ,  12.84],\n",
       "       [  3.  ,  12.93],\n",
       "       [  3.  ,  13.36],\n",
       "       [  3.  ,  13.52],\n",
       "       [  3.  ,  13.62],\n",
       "       [  3.  ,  12.25],\n",
       "       [  3.  ,  13.16],\n",
       "       [  3.  ,  13.88],\n",
       "       [  3.  ,  12.87],\n",
       "       [  3.  ,  13.32],\n",
       "       [  3.  ,  13.08],\n",
       "       [  3.  ,  13.5 ],\n",
       "       [  3.  ,  12.79],\n",
       "       [  3.  ,  13.11],\n",
       "       [  3.  ,  13.23],\n",
       "       [  3.  ,  12.58],\n",
       "       [  3.  ,  13.17],\n",
       "       [  3.  ,  13.84],\n",
       "       [  3.  ,  12.45],\n",
       "       [  3.  ,  14.34],\n",
       "       [  3.  ,  13.48],\n",
       "       [  3.  ,  12.36],\n",
       "       [  3.  ,  13.69],\n",
       "       [  3.  ,  12.85],\n",
       "       [  3.  ,  12.96],\n",
       "       [  3.  ,  13.78],\n",
       "       [  3.  ,  13.73],\n",
       "       [  3.  ,  13.45],\n",
       "       [  3.  ,  12.82],\n",
       "       [  3.  ,  13.58],\n",
       "       [  3.  ,  13.4 ],\n",
       "       [  3.  ,  12.2 ],\n",
       "       [  3.  ,  12.77],\n",
       "       [  3.  ,  14.16],\n",
       "       [  3.  ,  13.71],\n",
       "       [  3.  ,  13.4 ],\n",
       "       [  3.  ,  13.27],\n",
       "       [  3.  ,  13.17],\n",
       "       [  3.  ,  14.13]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_np[:, [0,alcohol_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to use Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = data_set_np[:, [alcohol_col, color_col]]\n",
    "y_np = data_set_np[:, 0]\n",
    "#color_np = data_set_np[:, color_col]\n",
    "indices = np.random.randint(0, n, n*80//100)\n",
    "x_train = x_np[indices]\n",
    "y_train = y_np[indices]\n",
    "test_indices = []\n",
    "for i in range(n):\n",
    "    if not (i in indices):\n",
    "        test_indices.append(i)\n",
    "x_test = x_np[test_indices]\n",
    "y_test = y_np[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = logReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3. 1. 1. 3. 1. 1. 1. 1. 1. 2. 3. 1. 1. 1. 2. 2. 1. 1. 3. 3. 3. 1. 1.\n",
      " 3. 2. 2. 3. 3. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 3. 2. 3. 3. 3. 1. 3. 3. 1. 3. 3.\n",
      " 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  4,  2],\n",
       "       [ 3, 27,  3],\n",
       "       [ 7,  2, 12]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plus_np = data_set_np[:, 1:]\n",
    "#y_plus_np = data_set_np[:, 0]\n",
    "x_plus_train = x_plus_np[indices]\n",
    "x_plus_test = x_plus_np[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_plus = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(x_plus_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22,  1,  0],\n",
       "       [ 3, 29,  1],\n",
       "       [ 0,  3, 16]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_plus_predict = logReg_plus.predict(x_plus_test)\n",
    "confusion_matrix(test_plus_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, test_plus_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
